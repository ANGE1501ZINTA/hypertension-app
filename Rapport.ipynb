{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52b8132",
   "metadata": {},
   "source": [
    "# Rapport Projet : Prédiction de l'Hypertension\n",
    "\n",
    "**Nom & Prenoms :** ZINTA ARTHUR ANGE EEMANUEL  \n",
    "**Date :** 04/12/2025  \n",
    "**Cours / Master :** Master Data Science\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "L’hypertension artérielle constitue un facteur majeur de risque cardiovasculaire.  \n",
    "Dans une démarche de prévention, ce projet vise à exploiter des données cliniques afin de prédire la probabilité qu’un patient développe une hypertension.\n",
    "\n",
    "Pour ce faire, j’ai réalisé :\n",
    "- une analyse exploratoire des données,\n",
    "- un prétraitement complet (nettoyage, standardisation, gestion des outliers),\n",
    "- puis l’entraînement de plusieurs modèles de Machine Learning : Logistic Regression, Random Forest et XGBoost.\n",
    "\n",
    "L’objectif final est d’identifier précocement les patients à risque et de proposer des mesures de prévention adaptées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15329f15",
   "metadata": {},
   "source": [
    "##  Description des données\n",
    "\n",
    "Le jeu de données utilisé contient des informations cliniques sur un ensemble de patients.  \n",
    "Ces variables permettent d’évaluer l’état de santé général et de détecter les facteurs pouvant influencer le risque d’hypertension.\n",
    "\n",
    "### Composition du dataset\n",
    "- **Nombre d’observations :** 70.000\n",
    "- **Nombre de variables :** 13\n",
    "- **Variable cible :** `cardio`\n",
    "  - 0 = Patient non hypertendu  \n",
    "  - 1 = Patient hypertendu  \n",
    "\n",
    "### Types de variables\n",
    "\n",
    "- continue : age , weight,height , ap_hi , ap_lo\n",
    "- categorielle : gender , gluc , cholesterol , smoke , alco , active , cardio\n",
    "Le tableau suivant montre un aperçu des premières lignes du dataset :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1a878",
   "metadata": {},
   "source": [
    "|    | id | age | gender | height | weight | ap_hi | ap_lo | cholesterol | gluc | smoke | alco | active | cardio |\n",
    "|----|----|-----|--------|--------|--------|-------|-------|-------------|------|-------|------|--------|--------|\n",
    "| 0  | 0  | 50  | 2      | 168    | 62.0   | 110   | 80    | 1           | 1    | 0     | 0    | 1      | 0      |\n",
    "| 1  | 1  | 55  | 1      | 156    | 85.0   | 140   | 90    | 3           | 1    | 0     | 0    | 1      | 1      |\n",
    "| 2  | 2  | 52  | 1      | 165    | 64.0   | 130   | 70    | 3           | 1    | 0     | 0    | 0      | 1      |\n",
    "| 3  | 3  | 48  | 2      | 169    | 82.0   | 150   | 100   | 1           | 1    | 0     | 0    | 1      | 1      |\n",
    "| 4  | 4  | 48  | 1      | 156    | 56.0   | 100   | 60    | 1           | 1    | 0     | 0    | 0      | 0      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e4d13",
   "metadata": {},
   "source": [
    "### VISUALISATION DE LA DISTRIBUTION DE LA TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c06826",
   "metadata": {},
   "source": [
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "bins = [-0.5, 0.5, 1.5]\n",
    "\n",
    "plt.hist(df['cardio'], bins=bins, color='skyblue', edgecolor='black', rwidth=0.8)\n",
    "plt.xticks([0, 1])  # s'assurer que seuls 0 et 1 apparaissent sur l'axe X\n",
    "plt.title(\"Distribution de la variable cible\")\n",
    "plt.xlabel(\"Cardio (0 = non hypertendu, 1 = hypertendu)\")\n",
    "plt.ylabel(\"Nombre de patients\")\n",
    "plt.show()\n",
    "()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696d383",
   "metadata": {},
   "source": [
    "![diribution_target](distribution_target.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57b2bc",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Il y a autant de patients atteints de maladies cardiovasculaires que de patients non atteints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a14aa1",
   "metadata": {},
   "source": [
    "## Prétraitement \n",
    "\n",
    "Le prétraitement a permis de nettoyer, normaliser et encoder les données pour les rendre exploitables par le modèle. Le dataset a ensuite été divisé en ensembles d’entraînement, de validation et de test, assurant un apprentissage efficace, un réglage optimal des hyperparamètres et une évaluation objective des performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f94f7",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# Créer la colonne BMI\n",
    "df[\"BMI\"] = df[\"weight\"] / (df[\"height\"]/100)**2\n",
    "\n",
    "# Filtrer les valeurs aberrantes (optionnel mais recommandé)\n",
    "df = df[(df[\"ap_hi\"] >= 80) & (df[\"ap_hi\"] <= 240)]\n",
    "df = df[(df[\"ap_lo\"] >= 50) & (df[\"ap_lo\"] <= 150)]\n",
    "df = df[(df[\"weight\"] >= 30) & (df[\"weight\"] <= 200)]\n",
    "df = df[(df[\"height\"] >= 140) & (df[\"height\"] <= 210)]\n",
    "\n",
    "# Séparer features et target\n",
    "X = df.drop(columns=[ \"cardio\"])\n",
    "y = df[\"cardio\"]\n",
    "\n",
    "# Split train/test/validation\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Standardisation des features numériques\n",
    "num_features = [\"age\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\", \"BMI\"]\n",
    "scaler = StandardScaler()\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_val[num_features] = scaler.transform(X_val[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dacac8",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177e1874",
   "metadata": {},
   "source": [
    "- Création de modèle machine learning pour entrainer nos données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff3ba3",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate_model(model, X_val, y_val, X_test, y_test):\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Performance sur le val set :\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_val, y_val_pred))\n",
    "    print(\"F1-score :\", f1_score(y_val, y_val_pred))\n",
    "    print(\"\\nPerformance finale sur le test set :\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_test, y_test_pred))\n",
    "    print(\"F1-score :\", f1_score(y_test, y_test_pred))\n",
    "    print(\"\\nClassification report :\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Modèles\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(solver='liblinear', random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Entraînement et évaluation\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Évaluation du modèle : {name} ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(model, X_val, y_val, X_test, y_test)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835d972",
   "metadata": {},
   "source": [
    "### Interpreation\n",
    "\n",
    "Après avoir entraîné plusieurs modèles et évalué leurs performances à l’aide de notre fonction d’évaluation, il ressort que **XGBoost** est le modèle le plus performant pour la prédiction.  \n",
    "Il obtient une **accuracy de 0.73 sur le jeu de test**, ce qui en fait le meilleur choix parmi les modèles testés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df48df5",
   "metadata": {},
   "source": [
    "### Optimisation des hyperparamètres du modèle choisi avec GridSearchCV\n",
    "\n",
    "Nous optimisons les hyperparamètres du modèle en utilisant GridSearchCV.\n",
    "Cette méthode teste toutes les combinaisons possibles d’hyperparamètres définies dans une grille afin de trouver celle qui donne les meilleures performances sur le jeu de validation.\n",
    "L’optimisation permet au modèle d’apprendre de manière plus efficace et d’améliorer sa précision sur les données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b91c18",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "evaluate_model(best_xgb, X_val, y_val, X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313bf6c8",
   "metadata": {},
   "source": [
    "### Test\n",
    "Après avoir entraîné plusieurs modèles et évalué leurs performances avec notre fonction d’évaluation, il ressort que **XGBoost est le modèle le plus performant**, atteignant une accuracy de **0,73** sur le jeu de test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe6117",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ordre des features utilisé dans ton modèle (doit correspondre à X_train)\n",
    "feature_order = ['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', \n",
    "                 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'BMI']\n",
    "scaler_features = ['age', 'height', 'weight', 'ap_hi', 'ap_lo', 'BMI']\n",
    "\n",
    "# Profils patients\n",
    "patient_healthy = {\n",
    "    'age': 70,\n",
    "    'gender': 1,\n",
    "    'height': 170,\n",
    "    'weight': 75,\n",
    "    'ap_hi': 120,\n",
    "    'ap_lo': 80,\n",
    "    'cholesterol': 1,\n",
    "    'gluc': 1,\n",
    "    'smoke': 0,\n",
    "    'alco': 0,\n",
    "    'active': 1,\n",
    "    'BMI': 75 / (1.70**2)\n",
    "}\n",
    "\n",
    "patient_risk = {\n",
    "    'age': 70,\n",
    "    'gender': 1,\n",
    "    'height': 170,\n",
    "    'weight': 120,\n",
    "    'ap_hi': 180,\n",
    "    'ap_lo': 110,\n",
    "    'cholesterol': 3,\n",
    "    'gluc': 3,\n",
    "    'smoke': 1,\n",
    "    'alco': 1,\n",
    "    'active': 0,\n",
    "    'BMI': 120 / (1.70**2)\n",
    "}\n",
    "\n",
    "# Créer DataFrame avec le bon ordre\n",
    "df_patients = pd.DataFrame([\n",
    "    [patient_healthy[col] for col in feature_order],\n",
    "    [patient_risk[col] for col in feature_order]\n",
    "], columns=feature_order)\n",
    "\n",
    "# Standardiser seulement les colonnes numériques\n",
    "df_patients[scaler_features] = scaler.transform(df_patients[scaler_features])\n",
    "\n",
    "# Prédictions\n",
    "pred_class = best_xgb.predict(df_patients)\n",
    "# Probabilités prédites pour nos patients\n",
    "pred_proba = best_xgb.predict_proba(df_patients)\n",
    "\n",
    "# Choisir un seuil personnalisé, par exemple 0.65\n",
    "threshold = 0.65\n",
    "\n",
    "# Classe prédite selon le seuil\n",
    "pred_class_custom = (pred_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# Affichage\n",
    "for i, patient_name in enumerate(['Sain', 'À risque']):\n",
    "    print(f\"\\nProfil {patient_name} :\")\n",
    "    print(\"Classe prédite (seuil 0.65) :\", pred_class_custom[i])\n",
    "    print(\"Probabilité d'hypertension :\", pred_proba[i])\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bfac5",
   "metadata": {},
   "source": [
    "### Resultat\n",
    "\n",
    "| Profil            | Classe prédite (seuil = 0.65) | P(0)          | P(1)          |\n",
    "|-------------------|-------------------------------|---------------|---------------|\n",
    "| **Profil Sain**   | 0                             | 0.3830126     | **0.6169874** |\n",
    "| **Profil À risque** | 1                           | 0.15896243    | **0.8410376** |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee6248",
   "metadata": {},
   "source": [
    "##  Learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1c266",
   "metadata": {},
   "source": [
    "## Learning Curve\n",
    "\n",
    "La *learning curve* est un outil d’évaluation qui permet d’analyser la capacité d’un modèle à apprendre progressivement.  \n",
    "Elle montre comment évoluent les performances du modèle sur :\n",
    "\n",
    "- **les données d’entraînement**,  \n",
    "- **les données de validation**,  \n",
    "\n",
    "au fur et à mesure que la quantité de données utilisées pour l’apprentissage augmente.\n",
    "\n",
    "Cette courbe met également en évidence :\n",
    "- **la moyenne des scores** obtenus,\n",
    "- **l’écart-type**, qui indique la stabilité ou la variabilité des performances.\n",
    "\n",
    "Elle permet ainsi d’identifier si le modèle souffre :\n",
    "- **d’overfitting** (trop bon sur train, mauvais sur validation),\n",
    "- **d’underfitting** (mauvais sur les deux),\n",
    "- ou s’il généralise correctement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66ee61",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "train_size , train_score, test_score = learning_curve (\n",
    "\n",
    "    estimator=best_xgb,\n",
    "    X= X_train,\n",
    "    y= y_train,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    train_sizes=np.linspace(0.1,1.0,10),\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81767814",
   "metadata": {},
   "source": [
    "![learning_curve](learning_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6432e72",
   "metadata": {},
   "source": [
    "###  Interprétation\n",
    "\n",
    "Sur la courbe d’apprentissage, le score d’accuracy finale obtenu sur les **données d’entraînement** est de **0.752**, tandis que celui obtenu sur les **données de validation** est de **0.735**.  \n",
    "\n",
    "L’écart entre les deux scores est faible, ce qui indique **l’absence de surapprentissage (overfitting)**.  \n",
    "Ainsi, le modèle parvient à généraliser correctement : ses performances en validation sont proches de celles observées à l’entraînement, ce qui témoigne d’une **prédiction fiable et stable**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc6a43",
   "metadata": {},
   "source": [
    "## Prise de décision \n",
    "\n",
    "Après avoir mener ce travail sur les données cliniques de different patient on envisage les decisions suivantes :\n",
    "\n",
    "\n",
    "| Probabilité prédite | Décision médicale           | Explication                                                                 |\n",
    "|-------------------|----------------------------|---------------------------------------------------------------------------|\n",
    "| **P < 0.30**       | Patient sain               | Aucun signe d’hypertension, simple suivi normal                           |\n",
    "| 0.30 ≤ P < 0.65    | Surveiller (risque modéré) | Recommandations : perte de poids, activité, vérifier la tension chaque mois |\n",
    "| **P ≥ 0.65**       | Patient à haut risque      | Doit être orienté pour dépistage + mesures préventives                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee1a69",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce projet a permis de développer un modèle de prédiction de l'hypertension basé sur des données cliniques, avec XGBoost un modèle de machine learning qui offre la meilleure performance. Les résultats montrent que notre approche peut aider à identifier les patients à risque et soutenir les actions de prévention.\n",
    "\n",
    "À l'avenir, ce modèle pourrait être enrichi avec des données supplémentaires, comme des habitudes alimentaires ou des mesures génétiques, afin d'améliorer encore la précision et de contribuer à une prévention plus personnalisée des maladies cardiovasculaires.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
